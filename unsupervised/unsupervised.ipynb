{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcba04-c1f5-4f20-9b1c-363a454f09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Dataset:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Display the first few rows\n",
    "print(X.head())\n",
    "\n",
    "#Drop the species column since this is a clustering problem.\n",
    "y = pd.Series(data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f4cdc-4d4f-4b9f-b0de-a4030783c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) KMeans Clustering (4 marks)\n",
    "\n",
    "#Provide a brief description of how KMeans clustering works.\n",
    "'''KMeans clustering is an iterative algorithm that divides a dataset into K distinct, non-overlapping subsets (clusters). \n",
    "The algorithm works as follows:\n",
    "\n",
    "Initialize K centroids randomly.\n",
    "Assign each data point to the nearest centroid.\n",
    "Recalculate the centroids as the mean of the assigned points.\n",
    "Repeat steps 2 and 3 until convergence (when assignments no longer change).'''\n",
    "\n",
    "#Explain why KMeans clustering might be suitable for the Iris dataset.\n",
    "'''KMeans is suitable for the Iris dataset because:\n",
    "\n",
    "The dataset has well-defined groups that can be separated in a multi-dimensional space.\n",
    "It allows for efficient clustering of the continuous numerical features (sepal length, sepal width, petal length, petal width).'''\n",
    "\n",
    "#Apply KMeans clustering to the preprocessed Iris dataset and visualize the clusters.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Choosing the number of clusters (K)\n",
    "k = 3  # Based on the known species in the dataset\n",
    "\n",
    "# Applying KMeans clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X)\n",
    "X['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualizing the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X['sepal length (cm)'], X['sepal width (cm)'], c=X['Cluster'], cmap='viridis', marker='o', edgecolor='k', s=100)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', s=200, alpha=0.75, marker='X')  # centroids\n",
    "plt.title('KMeans Clustering of Iris Dataset')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ed421-7c59-4903-a253-bc14232f1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B) Hierarchical Clustering (4 marks)\n",
    "\n",
    "#Provide a brief description of how Hierarchical clustering works.\n",
    "'''Hierarchical clustering builds a tree-like structure (dendrogram) to represent the relationships between data points. \n",
    "There are two main types:\n",
    "\n",
    "Agglomerative: Starts with each point as its own cluster and merges them based on proximity.\n",
    "Divisive: Starts with one cluster and recursively splits it into smaller clusters.'''\n",
    "\n",
    "#Explain why Hierarchical clustering might be suitable for the Iris dataset.\n",
    "'''Hierarchical clustering is suitable for the Iris dataset because:\n",
    "\n",
    "It does not require specifying the number of clusters in advance.\n",
    "The dendrogram can provide insights into the data structure and the relationships between clusters.'''\n",
    "\n",
    "#Apply Hierarchical clustering to the preprocessed Iris dataset and visualize the clusters.\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Applying Hierarchical clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=k)\n",
    "X['Hierarchical_Cluster'] = hierarchical.fit_predict(X)\n",
    "\n",
    "# Dendrogram\n",
    "plt.figure(figsize=(12, 7))\n",
    "linked = linkage(X.drop(['Cluster'], axis=1), method='ward')\n",
    "dendrogram(linked, orientation='top', labels=y, distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Dendrogram for Hierarchical Clustering')\n",
    "plt.xlabel('Iris Species')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing Hierarchical clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X['sepal length (cm)'], X['sepal width (cm)'], c=X['Hierarchical_Cluster'], cmap='viridis', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Hierarchical Clustering of Iris Dataset')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
